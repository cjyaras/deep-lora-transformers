{
    "identifier": null,
    "finetune_task_name": "cola",
    "max_seq_length": 128,
    "num_train_samples": 1024,
    "pretrain_model": "bert-base-cased",
    "lora_adapt_type": "all-dense",
    "lora_depth": 2,
    "lora_init_scale": 0.001,
    "lora_rank": 8,
    "lora_compress": false,
    "lora_gamma": 0,
    "num_train_steps": 1000,
    "train_batch_size": 16,
    "eval_batch_size": 32,
    "num_warmup_steps": 0,
    "learning_rate": 0.0001,
    "weight_decay": 0.0,
    "decay_ratio": 1.0,
    "log_eval_steps": 1000,
    "save_step_points": [],
    "save_dir": "experiments/few_shot_1024_final/cola"
}