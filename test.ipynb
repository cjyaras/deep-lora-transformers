{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 14:22:51.875036: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-30 14:22:51.875085: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-30 14:22:51.876411: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-30 14:22:52.931331: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import flax\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import configs\n",
    "import models\n",
    "import data\n",
    "import train\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_config = configs.TaskConfig()\n",
    "task_config.lora_compress = True\n",
    "task_config.lora_rank = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 14:23:07.540179: W external/xla/xla/service/gpu/nvptx_compiler.cc:698] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.3.107). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing FlaxBertForSequenceClassification: {('cls', 'predictions', 'bias'), ('cls', 'predictions', 'transform', 'LayerNorm', 'scale'), ('cls', 'predictions', 'transform', 'dense', 'kernel'), ('cls', 'predictions', 'transform', 'dense', 'bias'), ('cls', 'predictions', 'transform', 'LayerNorm', 'bias')}\n",
      "- This IS expected if you are initializing FlaxBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FlaxBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of FlaxBertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: {('bert', 'pooler', 'dense', 'kernel'), ('bert', 'pooler', 'dense', 'bias'), ('classifier', 'kernel'), ('classifier', 'bias')}\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "is_regression = task_config.finetune_task_name == \"stsb\"\n",
    "\n",
    "# Model\n",
    "pretrain_model = models.create_pretrain_model_from_config(\n",
    "    task_config, num_labels=data.task_to_num_labels[task_config.finetune_task_name]\n",
    ")\n",
    "\n",
    "learning_rate_fn = train.create_learning_rate_fn(\n",
    "    task_config.num_train_steps,\n",
    "    task_config.num_warmup_steps,\n",
    "    task_config.learning_rate,\n",
    "    task_config.decay_ratio,\n",
    ")\n",
    "\n",
    "train_step, eval_step = train.create_train_eval_step_fns(learning_rate_fn)\n",
    "\n",
    "model_state = train.create_model_state(\n",
    "    model=pretrain_model,\n",
    "    is_regression=is_regression,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ab49b217e2240169b3c3c6fa0aad4f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/deep-lora-transformers/experiments/stsb_lora_type=only-query-value_depth=3_rank=8_compress_lr=0.0001_steps=200_seed=0\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "train_dataset, eval_dataset = data.load_dataset_from_config(task_config, seed)\n",
    "\n",
    "rng = jax.random.PRNGKey(seed)\n",
    "\n",
    "lora_rng, rng = jax.random.split(rng)\n",
    "uncompressed_lora_state = train.create_lora_train_state(\n",
    "    task_config,\n",
    "    pretrain_model.params,  # type: ignore\n",
    "    learning_rate_fn=learning_rate_fn,\n",
    "    lora_rng=lora_rng,\n",
    ")\n",
    "\n",
    "experiment_path = utils.get_experiment_path(task_config, seed)\n",
    "print(experiment_path)\n",
    "\n",
    "dropout_rng, input_rng, rng = jax.random.split(rng, 3)\n",
    "train_iterator = data.create_train_iterator(\n",
    "    input_rng, train_dataset, task_config.train_batch_size\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
